{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c40729-4150-4c25-b695-d6f31973e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch \n",
    "import transformers\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078359a3-ba7b-4acf-adba-0c319f72396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51181d91-5b70-4344-afdc-4cb2ba9bf284",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328f8f07-1466-4ddd-b28d-f5004f871fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5466854-b560-4cdf-8840-1f080da14181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d258bb-dd43-4726-9ff4-924f9c962a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e8ee1b-a3c4-4101-8b91-d70acccf1414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, MarkdownTextSplitter, MarkdownHeaderTextSplitter\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_teddynote.retrievers import KiwiBM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever, MultiQueryRetriever\n",
    "from langchain.document_loaders import PDFPlumberLoader, PyMuPDFLoader, PyPDFLoader, UnstructuredPDFLoader\n",
    "\n",
    "import peft\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5260bf-a963-499f-b3de-d9937f183713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import Dataset\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b1cdc1-33d2-40ea-a1d7-126767cb73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForTokenClassification\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc414f-51d8-4af3-9e9c-c3da7e3700ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForTokenClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path = 't5-small'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb42f47-8465-458d-a324-5b4ffdd38f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 16\n",
    "tokenizer = T5ForTokenClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path= 't5-small'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89866a0-4173-44ae-94bd-dca8057c4e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacde6f9-2ae3-416e-9232-9a3f72616f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10d7a51-2b0d-47c6-a8fc-d89ed7c94910",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data['first_party'] + '[SEP]' + data['second_party'] +'[SEP]' + data['facts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241eaf36-9663-4e02-bd26-6fec415cec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8fc856-7d96-459c-a547-c02a9fb7518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232cd63c-a89c-4b7d-ac6b-2856a5d8bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)\n",
    "df = pd.concat([df, data['first_party_winner']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f0c5cb-62f7-4471-bd33-06725882c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['infos', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ddb929-1bbc-4770-987b-6b08adc6a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e862ef2b-7bd3-4dc5-9a12-6594080c3244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb29d31c-fa91-476f-bb9e-c53c71d87672",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d767b-db12-4969-b0a5-e4caace1f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds.cpu().numpy(), axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eacfff1-c7e5-41b9-ba96-ff6592356958",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7d9516-62ba-40c4-b52f-f16b62217351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data, tokenizer, device):\n",
    "    combined_text = (data['first_party'] + \" [SEP] \" + data['second_party'] + \" [SEP] \" + data['facts']).tolist()\n",
    "\n",
    "    tokenizer = tokenizer(\n",
    "        combined_text,\n",
    "        padding = 'longest',\n",
    "        truncation = True,\n",
    "        return_tensors = 'pt'\n",
    "    )\n",
    "    input_ids = tokenized['input_ids']\n",
    "    attention_mask = tokenized['attention_mask']\n",
    "    labels = torch.tensor(data.iloc[:, 1].values, dtype = torch.long)\n",
    "    return TensorDataset(input_ids, attention_mask, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b29153f-30f8-43ee-b836-4dd8caf042ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f538f2-4d37-494a-b9f1-ec5b67796804",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs.logits.shape) \n",
    "print(labels.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b5c12-1271-4c1e-9c9c-91b200b7e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf8ce46-4698-4558-9863-8dd50eeae534",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, -1] = df.iloc[:, -1].replace('positive', 1).replace('negative', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fae773-cfd9-4b27-87f7-b1df3cf70205",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa8b6d-d040-41de-8176-c68de33ceca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data.iloc[:, -1].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1fdd13-a468-4fad-8601-6c44e486ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44396399-1937-4363-a7fd-ea40bfbf2ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:, -1].astype(str).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237ab9c1-ccf9-4205-9f98-01916435d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data.iloc[:, -1].astype(str).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9160e241-6590-481e-9067-c442fe719353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data, tokenizer, device):\n",
    "    source = tokenizer(\n",
    "        text = data.infos.tolist(),\n",
    "        padding='max_length',\n",
    "        max_length=128,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # target = tokenizer(\n",
    "    #     text = data.label.tolist(),\n",
    "    #     padding='max_length',\n",
    "    #     max_length=128,\n",
    "    #     pad_to_max_length= True,\n",
    "    #     truncation = True,\n",
    "    #     return_tensors = 'pt'\n",
    "    # )\n",
    "\n",
    "    # data.iloc[:, -1] = data.iloc[:, -1].astype(str)\n",
    "    # data.iloc[:, -1] = data.iloc[:, -1].replace('1', 'positive').replace('0', 'negative')\n",
    "\n",
    "    # target = tokenizer(\n",
    "    #     text=data.label.tolist(),\n",
    "    #     padding='max_length',\n",
    "    #     max_length=128,\n",
    "    #     truncation=True,\n",
    "    #     return_tensors='pt'\n",
    "    # )\n",
    "\n",
    "\n",
    "    target = data.label.astype(int).values\n",
    "    \n",
    "    input_ids = source['input_ids'].squeeze().to(device)\n",
    "    attention_mask = source['attention_mask'].squeeze().to(device)\n",
    "    # labels = target['input_ids'].to(device)\n",
    "    labels = torch.tensor(target).to(device)\n",
    "    \n",
    "    return TensorDataset(input_ids, attention_mask, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3120c356-8a92-49e7-bccd-7bdf441a366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path= 't5-small'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c23219-f001-4c17-9430-141207db69f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e3cacb-9487-404d-a7df-99666bc4ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dataset(df, tokenizer, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c5a525-87ca-4436-9be3-3928f05364e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(dataset, sampler, batch_size):\n",
    "    data_sampler = sampler(dataset)\n",
    "    dataloader = DataLoader(dataset, sampler = data_sampler, batch_size = batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4e75f1-acc1-4376-aa99-03d7591c0182",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid, test = np.split(\n",
    "    df.sample(frac=1, random_state=42), [int(0.6*len(df)), int(0.8*len(df))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75736180-0805-45cd-9ddb-f79368712adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(train_data, tokenizer, device='cpu')\n",
    "train_dataloader = get_dataloader(train_dataset, RandomSampler, batch_size)\n",
    "\n",
    "valid_dataset = make_dataset(valid, tokenizer, device='cpu')\n",
    "valid_dataloader = get_dataloader(valid_dataset, RandomSampler, batch_size)\n",
    "\n",
    "test_dataset = make_dataset(test, tokenizer, device='cpu')\n",
    "test_dataloader = get_dataloader(test_dataset, RandomSampler, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415b5ea-fddd-43f6-af50-744a717ef65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3873a90d-a706-48f5-a482-4aadb318e200",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-5, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ba879c-18ab-44eb-99f4-6f183e7c7ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for input_ids, attention_mask, labels in dataloader:\n",
    "        outputs = model(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            labels = labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ca861-d343-467f-88e1-f60540a27217",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb0dead-da04-442b-9cd6-9468e1d3d714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb2eba7-158f-4619-b213-eadd235a0c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for input_ids, attention_mask, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        loss = loss.\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    return train_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd8ae4-28a6-4495-b743-c6dc92ff0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        input_ids = batch[0]\n",
    "        attention_mask = batch[1]\n",
    "        labels = batch[2]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        # Compute loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Reshape logits and labels for CrossEntropyLoss\n",
    "        logits = logits.view(-1, logits.size(-1))  # Shape: (batch_size * sequence_length, num_labels)\n",
    "        labels = labels.view(-1)                    # Shape: (batch_size * sequence_length)\n",
    "        \n",
    "        loss_fct = torch.nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(logits, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6297aad-b875-40b0-9e84-12b5e9c101b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluation(model, dataloader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        val_loss, val_accuracy = 0.0, 0.0\n",
    "        \n",
    "        for input_ids, attention_mask, labels in dataloader:\n",
    "            outputs = model(\n",
    "                input_ids = input_ids,\n",
    "                attention_mask = attention_mask,\n",
    "                labels = labels\n",
    "            )\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            loss = criterion(logits, labels)\n",
    "            logtis = logits.detach().cpu().numpy()\n",
    "            labels_ids = labels.to('cpu').numpy()\n",
    "            accuracy = calc_accuracy(logits, labels_ids)\n",
    "            \n",
    "            val_loss += loss\n",
    "            val_accuracy += accuracy\n",
    "            \n",
    "        val_loss = val_loss/len(dataloader)\n",
    "        val_accuracy = val_accuracy / len(dataloader)\n",
    "        return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e17da6-64b2-4182-8fa5-17d21009d6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "16*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06deefb1-4ecb-45d9-bd6f-1adcc6c79b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(type(batch))\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18581a8b-9f27-4f4a-9f0a-4df130465121",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = 10000\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, optimizer, train_dataloader)\n",
    "    val_loss, val_accuracy = evaluation(model, valid_dataloader)\n",
    "    print(f'Epoch: {epoch+1} train loss: {train_loss:.4f} val loss: {val_loss:.4f} val_acc: {val_accuracy:.4f}')\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63f206f-f125-43f5-94f0-d5efcfc77c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fc0825-3bc9-432c-8038-12562773dd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40c4a32-ee61-4135-95ea-866d653a32fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576f7b0-7001-4bff-9b05-f4ff1cae9ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685bb88f-d8eb-4c30-8248-b6383896782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.loc[209, 'infos']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
